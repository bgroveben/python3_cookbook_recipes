{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Writing your own programming language and compiler with Python](https://blog.usejournal.com/writing-your-own-programming-language-and-compiler-with-python-a468970ae6df)  \n",
    "### Thank You [Marcelo](https://blog.usejournal.com/@marcelogdeandrade)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to help people that are seeking a way to start developing their first programming language/compiler.  \n",
    "The original author's source code can be [found on Github](https://github.com/marcelogdeandrade/PythonCompiler)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using [PLY](http://www.dabeaz.com/ply/) as [lexer](https://en.wikipedia.org/wiki/Lexical_analysis) and [parser](), and [LLVMlite](http://llvmlite.readthedocs.io/en/latest/) as low level intermediate language to do code generation with optimizations.  \n",
    "If you don't want to look that information up now, that's fine because we'll cover the relevant parts later.  \n",
    "Also, the LLVM documentation contains a helpful tutorial called [Kaleidoscope: Implementing a Language with LLVM](https://llvm.org/docs/tutorial/index.html#kaleidoscope-implementing-a-language-with-llvm) that covers many of the same topics as this project.  \n",
    "Some of the material in this notebook is for more experienced programmers, so make sure you do a bit of homework on [RPLY](https://github.com/alex/rply), which we'll be using instead of PLY, as well as [LLC](https://llvm.org/docs/CommandGuide/llc.html) and [GCC](https://gcc.gnu.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where shall we begin, anyway?  \n",
    "A good start is to define a language, which we can call **TOY** for now."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "var x;\n",
    "x := 4 + 4 * 2;\n",
    "    if (x > 3) {\n",
    "        x := 2;\n",
    "    } else {\n",
    "        x := 5;\n",
    "    }\n",
    "print(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks straighforward, but how do we implement that with our programming language?  \n",
    "We can break that code down into a simpler example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(4 + 4 - 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for machines to process the instructions you give them, they have to be given a defined grammar structure.  \n",
    "[EBNF](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form) is used to make a formal description of a language which can be a computer programming language.  \n",
    "The original author of this tutorial recommends [this post](https://tomassetti.me/ebnf/) for a deeper look at how EBNF grammar works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What the EBNF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create a EBNF that describes the minimal possible functionality of TOY, which is a sum operation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4 + 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the EBNF:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "expression = number, \"+\", number, \";\";\n",
    "number = digit+;\n",
    "digit = [0-9];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the underlying structure of the language isn't easy to spot yet, that's okay.  \n",
    "You'll get better at spotting the patterns with more practice.  \n",
    "Our programming language will need a bit more functionality to actually be useful.  \n",
    "First, we want to be able to add as many numbers as we wish.  \n",
    "Second, we want to be able to do subtraction as well."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4 + 4 -2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the EBNF:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "expression = number, { (\"+\"|\"-\"), number }, \";\";\n",
    "number = digit+;\n",
    "digit = [0-9];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need some output, so let's add print functionality."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(4 + 4 - 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our resulting EBNF will be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "program = \"print\", \"(\", expression, \")\", \";\";\n",
    "expression = number, { (\"+\"|\"-\"), number } ;\n",
    "number = digit+\n",
    "digit = [0-9];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined a basic grammar, so now we can move on to translating it to code and writing a program.  \n",
    "We will be answering two questions:  \n",
    "Can we translate the grammar to code in a way that we can validate and understand?  \n",
    "After that, can we compile that code into a binary executable?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compiler is a program that turns a programming language into another language, in this case machine language.  \n",
    "In this guide, We'll compile our programming language into LLVM IR and then into machine language.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compiling_process](img/compiling_process.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LLVM, it is possible to optimize your compilation without learning compiling optimization, and LLVM has a really good library to work with compilers.  \n",
    "Our compiler can be divided into three components:  \n",
    "* Lexer  \n",
    "* Parser  \n",
    "* Code Generator  \n",
    "For the Lexer and Parser we’ll be using RPLY, which is similar to PLY, but with a more robust API.  \n",
    "And for the Code Generator, we’ll use LLVMlite, a Python library for binding LLVM components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role of the **Lexer** is to take the program as input and divide it into *tokens*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tokenizing](img/tokenizing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the minimal structures form our EBNF to define our tokens."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(4 + 4 - 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our lexer will divide the statement above into the following list of tokens:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Token('PRINT', 'print')\n",
    "Token('OPEN_PAREN', '(')\n",
    "Token('NUMBER', '4')\n",
    "Token('SUM', '+')\n",
    "Token('NUMBER', '4')\n",
    "Token('SUB', '-')\n",
    "Token('NUMBER', '2')\n",
    "Token('CLOSE_PAREN', ')')\n",
    "Token('SEMI_COLON', ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to begin coding our compiler.  \n",
    "Create a file in this directory named `lexer.py`.  \n",
    "This file exists to define our tokens.  \n",
    "We will use the `LexerGenerator` class from RPLY to create our lexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexer.py\n",
    "\n",
    "from rply import LexerGenerator\n",
    "\n",
    "\n",
    "class Lexer():\n",
    "    def __init__(self):\n",
    "        self.lexer = LexerGenerator()\n",
    "\n",
    "    def _add_tokens(self):\n",
    "        # print\n",
    "        self.lexer.add('PRINT', r'print')\n",
    "        # parentheses\n",
    "        self.lexer.add('OPEN_PAREN', r'\\(')\n",
    "        self.lexer.add('CLOSE_PAREN', r'\\)')\n",
    "        # semicolon\n",
    "        self.lexer.add('SEMI_COLON', r'\\;')\n",
    "        # addition and subtraction operators\n",
    "        self.lexer.add('SUM', r'\\+')\n",
    "        self.lexer.add('SUB', r'\\-')\n",
    "        # number\n",
    "        self.lexer.add('NUMBER', r'\\d+')\n",
    "        # ignore spaces\n",
    "        self.lexer.ignore('\\s+')\n",
    "\n",
    "    def get_lexer(self):\n",
    "        self._add_tokens()\n",
    "        return self.lexer.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `main.py` file that we can use to coordinate the compiler's 3 components.  \n",
    "After you run the next cell, you should see all of the tokens in the input text printed out in the correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token('PRINT', 'print')\n",
      "Token('OPEN_PAREN', '(')\n",
      "Token('NUMBER', '4')\n",
      "Token('SUM', '+')\n",
      "Token('NUMBER', '4')\n",
      "Token('SUB', '-')\n",
      "Token('NUMBER', '2')\n",
      "Token('CLOSE_PAREN', ')')\n",
      "Token('SEMI_COLON', ';')\n"
     ]
    }
   ],
   "source": [
    "from lexer import Lexer\n",
    "\n",
    "text_input = \"\"\"print(4 + 4 - 2);\"\"\"\n",
    "\n",
    "lexer = Lexer().get_lexer()\n",
    "tokens = lexer.lex(text_input)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the `python main.py` command, the output should be the same as above.  \n",
    "The token names can be anything you want, just make sure that they are consistent with the parser we're going to build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second component of our compiler is the **Parser**, which analyzes the program's syntax.  \n",
    "Basically, the parser takes the list of tokens created by the lexer and creates a data structure called an [Abstract Syntax Tree(AST)](https://en.wikipedia.org/wiki/Abstract_syntax_tree) as output.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lexical Analysis](img/lexical_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement our parser, we’ll use the structure created with out EBNF as model.  \n",
    "RPLY’s parser uses a format similar to the EBNF, so it's pretty straightforward.  \n",
    "Create a new file named `ast.py` that will contain all classes that are going to be called on the parser and create the AST."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class Number():\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def eval(self):\n",
    "        return int(self.value)\n",
    "\n",
    "\n",
    "class BinaryOp():\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "class Sum(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() + self.right.eval()\n",
    "\n",
    "\n",
    "class Sub(BinaryOp):\n",
    "    def eval(self):\n",
    "        return self.left.eval() - self.right.eval()\n",
    "\n",
    "\n",
    "class Print():\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "    def eval(self):\n",
    "        print(self.value.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create the parser using `ParserGenerator` from RPLY.  \n",
    "Create a file named `parser.py`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from rply import ParserGenerator\n",
    "from ast import Number, Sum, Sub, Print\n",
    "\n",
    "\n",
    "class Parser():\n",
    "    def __init__(self):\n",
    "        self.pg = ParserGenerator(\n",
    "            # A list of all token names accepted by the parser.\n",
    "            ['NUMBER', 'PRINT', 'OPEN_PAREN', 'CLOSE_PAREN',\n",
    "             'SEMI_COLON', 'SUM', 'SUB']\n",
    "        )\n",
    "\n",
    "    def parse(self):\n",
    "        @self.pg.production('program : PRINT OPEN_PAREN expression CLOSE_PAREN SEMI_COLON')\n",
    "        def program(p):\n",
    "            return Print(p[2])\n",
    "\n",
    "        @self.pg.production('expression : expression SUM expression')\n",
    "        @self.pg.production('expression : expression SUB expression')\n",
    "        def expression(p):\n",
    "            left = p[0]\n",
    "            right = p[2]\n",
    "            operator = p[1]\n",
    "            if operator.gettokentype() == 'SUM':\n",
    "                return Sum(left, right)\n",
    "            elif operator.gettokentype() == 'SUB':\n",
    "                return Sub(left, right)\n",
    "\n",
    "        @self.pg.production('expression : NUMBER')\n",
    "        def number(p):\n",
    "            return Number(p[0].value)\n",
    "\n",
    "        @self.pg.error\n",
    "        def error_handle(token):\n",
    "            raise ValueError(token)\n",
    "\n",
    "    def get_parser(self):\n",
    "        return self.pg.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to update our `main.py` file so that the Parser and Lexer can communicate with each other."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lexer import Lexer\n",
    "from parser import Parser\n",
    "\n",
    "text_input = \"\"\"print(4 + 4 - 2);\"\"\"\n",
    "\n",
    "lexer = Lexer().get_lexer()\n",
    "tokens = lexer.lex(text_input)\n",
    "\n",
    "pg = Parser()\n",
    "pg.parse()\n",
    "parser = pg.get_parser()\n",
    "parser.parse(tokens).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the command  \n",
    "`$ python main.py`  \n",
    "you will see the correct output, which is a printed 6, but there is the matter of  \n",
    "`parser.py:38: ParserGeneratorWarning: 4 shift/reduce conflicts return self.pg.build()`  \n",
    "to deal with, so there is still work to be done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with these two components in place, we have a working compiler that can translate our TOY language using Python.  \n",
    "Now we have to work on creating machine language code, and then we'll need some optimization as well.  \n",
    "Get ready for code generation using LLVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Code Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third and last component of out compiler is the **Code Generator**.  \n",
    "It transforms the AST created from the parser into machine language or an IR.  \n",
    "In this case, it’s going to transform the AST into an [LLVM IR](https://llvm.org/docs/tutorial/LangImpl03.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLVM can be really complex to understand, so if you wish to fully understand what is going on, I recommend reading the [LLVMlite documentation](http://llvmlite.readthedocs.io/en/latest/).  \n",
    "LLVMlite doesn’t have a print function, so you have to define your own.  \n",
    "To start, let’s create a file named `codegen.py` that will contain the class `CodeGen`.  \n",
    "This class configures the LLVM and saves the IR code.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from llvmlite import ir, binding\n",
    "\n",
    "\n",
    "class CodeGen():\n",
    "    def __init__(self):\n",
    "        self.binding = binding\n",
    "        self.binding.initialize()\n",
    "        self.binding.initialize_native_target()\n",
    "        self.binding.initialize_native_asmprinter()\n",
    "        self._config_llvm()\n",
    "        self._create_execution_engine()\n",
    "        self._declare_print_function()\n",
    "\n",
    "    def _config_llvm(self):\n",
    "        self.module = ir,Module(name=__file__)\n",
    "        self.module.triple = self.binding.get_default_triple()\n",
    "        func_type = ir.FunctionType(ir.VoidType(), [], False)\n",
    "        base_func = ir.Function(self.module, func_type, name=\"main\")\n",
    "        block = base_func.append_basic_block(name=\"entry\")\n",
    "        self.builder = ir.IRBuilder(block)\n",
    "\n",
    "    def _create_execution_engine(self):\n",
    "        \"\"\"\n",
    "        Create an ExecutionEngine for JIT code generation on the host CPU\n",
    "        \"\"\"\n",
    "        target = self.binding.Target.from_default_triple()\n",
    "        target_machine = target.create_target_machine()\n",
    "        # Leave the backing module empty\n",
    "        backing_mod = binding.parse_assembly(\"\")\n",
    "        engine = binding.create_mcjit_compiler(backing_mod, target_machine)\n",
    "        self.engine = engine\n",
    "\n",
    "    def _declare_print_function(self):\n",
    "        voidptr_ty = ir.IntType(8).as_pointer()\n",
    "        printf_ty = ir.functionType(ir.IntType(32), [voidptr_ty], var_arg=True)\n",
    "        printf = ir.Function(self.module, printf_ty, name=\"printf\")\n",
    "        self.printf = printf\n",
    "\n",
    "    def _compile_ir(self):\n",
    "        \"\"\"\n",
    "        Compile the LLVM-IR string with the given engine.\n",
    "        Return the compiled module object.\n",
    "        \"\"\"\n",
    "        self.buildder.ret_void()\n",
    "        llvm_ir = str(self.module)\n",
    "        mod = self.binding.parse_assembly(llvm_ir)\n",
    "        mod.verify()\n",
    "        # Now we can add the module\n",
    "        self.engine.add_module(mod)\n",
    "        self.engine.finalize_object()\n",
    "        self.engine.run_static_constructors()\n",
    "        return mod\n",
    "\n",
    "        def create_ir(self):\n",
    "            self._compile_ir()\n",
    "\n",
    "        def save_ir(self, filename):\n",
    "            with open(filename, 'w') as output_file:\n",
    "                output_file.write(str(self.module))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must update our `main.py` file so that we can call our `CodeGen` methods.  \n",
    "Instead of hard_coding the input, store the input `print(4 + 4 + 2);` in a file named `input.toy`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lexer import Lexer\n",
    "from parser import Parser\n",
    "from codegen import CodeGen\n",
    "\n",
    "\n",
    "fname = \"input.toy\"\n",
    "with open(fname) as f:\n",
    "    text_input = f.read()\n",
    "\n",
    "lexer = Lexer().get_lexer()\n",
    "tokens = lexer.lex(text_input)\n",
    "codegen = CodeGen()\n",
    "\n",
    "module = codegen.module\n",
    "builder = codegen.builder\n",
    "printf = codegen.printf\n",
    "\n",
    "pg = Parser()\n",
    "pg.parse()\n",
    "parser = pg.get_parser()\n",
    "parser.parse(tokens).eval()\n",
    "\n",
    "coedgen.create_ir()\n",
    "codegen.save_ir(\"output.ll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important change in the code above involves passing the `module`, `builder`, and `printf` objects to the parser.  \n",
    "Now we can pass objects directly to the AST where the [LLVM-AST](https://llvm.org/docs/tutorial/LangImpl02.html) is created.  \n",
    "To do this, we must update the `parser.py` file to receive those objects and pass them on to the AST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
